{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Импорт библеотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# проведение пути до собственных модулей\n",
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# основные модули\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# собственные модулей\n",
    "from src.utils import prefilter_items\n",
    "from src.metrics import precision_at_k, recall_at_k, evaluate_pred\n",
    "# модель для 1го уровня\n",
    "from src.recommenders import MainRecommender\n",
    "\n",
    "# модели для 2го уровня\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# отключение предупреждений\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# создание датафреймов\n",
    "train = pd.read_csv('retail_train.csv')\n",
    "test = pd.read_csv('retail_test1.csv')\n",
    "\n",
    "# зегрузка фичей\n",
    "item_features = pd.read_csv('product.csv')\n",
    "user_features = pd.read_csv('hh_demographic.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Редактирование датафреймов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Снижение регистров столбцов\n",
    "item_features.columns = [col.lower() for col in item_features.columns]\n",
    "user_features.columns = [col.lower() for col in user_features.columns]\n",
    "\n",
    "# Переименование столбцов\n",
    "item_features.rename(columns={'product_id': 'item_id'}, inplace=True)\n",
    "user_features.rename(columns={'household_key': 'user_id'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## добавление фичей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# объединение датафреймов\n",
    "train_ = train.merge(item_features, on='item_id', how='left')\n",
    "train_ = train.merge(user_features, on='user_id', how='left')\n",
    "\n",
    "test_ = test.merge(item_features, on='item_id', how='left')\n",
    "test_ = test.merge(user_features, on='user_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# префильтрация\n",
    "train_, test_ = map(prefilter_items, (train_, test_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обучение одноуровневой модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:OpenBLAS detected. Its highly recommend to set the environment variable 'export OPENBLAS_NUM_THREADS=1' to disable its internal multithreading\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68ce71db99664d5480874765acb934d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2caf76be17c460ea1e395945cac7aef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5001.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# обучение одноуровневой модели\n",
    "recommender_ = MainRecommender(train_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[999999, 883616, 940947, 959219, 991024, 10049...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[999999, 866211, 885023, 899624, 940947, 95141...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>[989069, 1130858]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>[847738, 999999, 948650, 1082398, 1100159, 127...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>[859987, 863407, 895454, 999999, 930918, 95467...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                                             actual\n",
       "0        1  [999999, 883616, 940947, 959219, 991024, 10049...\n",
       "1        2  [999999, 866211, 885023, 899624, 940947, 95141...\n",
       "2        3                                  [989069, 1130858]\n",
       "3        6  [847738, 999999, 948650, 1082398, 1100159, 127...\n",
       "4        7  [859987, 863407, 895454, 999999, 930918, 95467..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# создание фрейма результатов одноуровневой модели\n",
    "result_ = test_.groupby('user_id')['item_id'].unique().reset_index()\n",
    "result_.columns = ['user_id', 'actual']\n",
    "\n",
    "# удаление тех пользователей, на которых модель не обучалась\n",
    "result_ = result_[result_['user_id'].isin(train_['user_id'])]\n",
    "result_.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## подбор числа кондидатов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# подбор числа кандидатов\n",
    "N_tuple = 50, 100, 200, 400\n",
    "metric = 'recall@k'\n",
    "\n",
    "# фрейм результатов прогноза\n",
    "recall_frame = pd.DataFrame(\n",
    "    columns=[metric, 'similar_items', 'als', 'own']\n",
    ").set_index(metric)\n",
    "\n",
    "# прогнозирование результатов и добавление во фрейм\n",
    "for N in N_tuple:\n",
    "    result_['similar_items'] = result_['user_id'].apply(\n",
    "        lambda x: recommender_.get_similar_items_recommendation(user=x, N=N)\n",
    "    )# apply\n",
    "\n",
    "    result_['als'] = result_['user_id'].apply(\n",
    "        lambda x: recommender_.get_als_recommendations(user=x, N=N)\n",
    "    )# apply\n",
    "\n",
    "    result_['own'] = result_['user_id'].apply(\n",
    "        lambda x: recommender_.get_own_recommendations(user=x, N=N)\n",
    "    )# apply\n",
    "    \n",
    "    recall_frame.loc[N] = evaluate_pred(data=result_, true='actual', metric=metric, k=N)\n",
    "\n",
    "recall_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 100 кондидатов на модели __own recommendation__ (основанной на Item Item Recommender) будет достаточно"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## прогнозирование результатов на трейне (precision@5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# подбор числа кандидатов\n",
    "N = 100\n",
    "k = 5\n",
    "metric = 'precision@k'\n",
    "\n",
    "precision_frame = pd.DataFrame(\n",
    "    columns=[metric, 'similar_items', 'als', 'own']\n",
    ").set_index(metric)\n",
    "\n",
    "# прогнозирование результатов и добавление ление во фрейм\n",
    "result_['similar_items'] = result_['user_id'].apply(\n",
    "    lambda x: recommender_.get_similar_items_recommendation(user=x, N=N)\n",
    ")# apply\n",
    "\n",
    "result_['als'] = result_['user_id'].apply(\n",
    "    lambda x: recommender_.get_als_recommendations(user=x, N=N)\n",
    ")# apply\n",
    "\n",
    "result_['own'] = result_['user_id'].apply(\n",
    "    lambda x: recommender_.get_own_recommendations(user=x, N=N)\n",
    ")# apply\n",
    "    \n",
    "precision_frame.loc[k] = evaluete_rec(data=result_, true='actual', metric=metric, k=k)\n",
    "\n",
    "precision_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вывод:\n",
    "\n",
    "- Видно что лучший точность у __own recommender__ (Item Item Recommender) однако она все же < 0.27. \n",
    "- Попробуем двухуровневую модель с фильтрацией товаров на 1м ровне."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# результат прогноза 100 кондидатов\n",
    "result_.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обучение двухуровневой модели\n",
    "\n",
    "## Обучение 1го уровня модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# разбиение на тестовые и трейновые фреймы 1го и 2го уровня\n",
    "weeks = 9\n",
    "\n",
    "# 1й уровень\n",
    "train_lvl1 = train_[train_['week_no'] < train_['week_no'].max() - weeks]\n",
    "test_lvl1 = train_[train_['week_no'] >= train_['week_no'].max() - weeks]\n",
    "\n",
    "# 2й уровень\n",
    "train_lvl2 = test_lvl1.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# обучение 1го уровня модели\n",
    "recommender_lvl1 = MainRecommender(train_lvl1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# создание фрейма результатов 1го уровня\n",
    "result_lvl1 = test_lvl1.groupby('user_id')['item_id'].unique().reset_index()\n",
    "result_lvl1.columns = ['user_id', 'actual']\n",
    "\n",
    "# удаление тех пользователей, на которых модель не обучалась\n",
    "result_lvl1 = result_lvl1[result_lvl1['user_id'].isin(train_lvl1['user_id'])]\n",
    "result_lvl1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# подбор числа кандидатов\n",
    "N_tuple = 50, 100, 200, 400\n",
    "metric = 'recall@k'\n",
    "\n",
    "# фрейм результатов прогноза\n",
    "recall_lvl1 = pd.DataFrame(columns=[metric, 'similar_items', 'als', 'own']).set_index(metric)\n",
    "\n",
    "for N in N_tuple:\n",
    "    result_lvl1['similar_items'] = result_lvl1['user_id'].apply(\n",
    "        lambda x: recommender_lvl1.get_similar_items_recommendation(user=x, N=N)\n",
    "    )# apply\n",
    "\n",
    "    result_lvl1['als'] = result_lvl1['user_id'].apply(\n",
    "        lambda x: recommender_lvl1.get_als_recommendations(user=x, N=N)\n",
    "    )# apply\n",
    "\n",
    "    result_lvl1['own'] = result_lvl1['user_id'].apply(\n",
    "        lambda x: recommender_lvl1.get_own_recommendations(user=x, N=N)\n",
    "    )# apply\n",
    "\n",
    "    recall_lvl1.loc[N] = evaluete_rec(data=result_lvl1, true='actual', metric=metric, k=N)\n",
    "    \n",
    "recall_lvl1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 100 кондидатов на модели __own recommendation__ (основанной на Item Item Recommender) будет достаточно"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# подбор числа кандидатов\n",
    "N = 100\n",
    "k = 5\n",
    "metric = 'precision@k'\n",
    "\n",
    "precision_lvl1 = pd.DataFrame(\n",
    "    columns=[metric, 'similar_items', 'als', 'own']\n",
    ").set_index(metric)\n",
    "\n",
    "# прогнозирование результатов и добавление во фрейм\n",
    "result_lvl1['similar_items'] = result_lvl1['user_id'].apply(\n",
    "    lambda x: recommender_lvl1.get_similar_items_recommendation(user=x, N=N)\n",
    ")# apply\n",
    "\n",
    "result_lvl1['als'] = result_lvl1['user_id'].apply(\n",
    "    lambda x: recommender_lvl1.get_als_recommendations(user=x, N=N)\n",
    ")# apply\n",
    "\n",
    "result_lvl1['own'] = result_lvl1['user_id'].apply(\n",
    "    lambda x: recommender_lvl1.get_own_recommendations(user=x, N=N)\n",
    ")# apply\n",
    "    \n",
    "precision_lvl1.loc[k] = evaluete_rec(data=result_lvl1, true='actual', metric=metric, k=k)\n",
    "\n",
    "precision_lvl1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Видно, что самое точное прогнозирование у __own recommender__ (Item Item Recommender) - __precision@5 = 0.31__ - его будем использовать для 2го уровня модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_lvl1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение 2го уровня модели\n",
    "\n",
    "### Формирование фремов для обучения на train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# формирование фрейма с результатами прогнозирования 1го уровня для 2го уровня\n",
    "result_lvl2 = pd.DataFrame(train_lvl2['user_id'].unique())\n",
    "result_lvl2.columns = ['user_id']\n",
    "\n",
    "# отбор пользователей для горячего старта\n",
    "train_users = train_lvl1['user_id'].unique()\n",
    "result_lvl2 = result_lvl2[result_lvl2['user_id'].isin(train_users)]\n",
    "\n",
    "# Добавление по 100 items которые отбирает 1 уровень модели\n",
    "result_lvl2['candidates'] = result_lvl2['user_id'].apply(lambda x: recommender_lvl1.get_own_recommendations(x, N=100))\n",
    "\n",
    "result_lvl2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# формирование фрейма для 2го уровня модели\n",
    "\n",
    "# вытаскиваем всех пользователей\n",
    "users_array = result_lvl2['user_id'].values\n",
    "\n",
    "# вытаскиваем все items\n",
    "candidates_lists = result_lvl2['candidates']\n",
    "len_candidates= len(candidates_lists[0])\n",
    "candidates_array = candidates_lists.values\n",
    "\n",
    "# формируем фрейм с спрогнозированными результатами\n",
    "df = pd.DataFrame({'user_id':users_array.repeat(len_candidates),\n",
    "                   'item_id':np.concatenate(candidates_array)})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Формируем фрейм рекоммендаций user_item\n",
    "\n",
    "# фиксируем фактическое взаимодействие\n",
    "targets_train_lvl2 = train_lvl2[['user_id', 'item_id']].copy()\n",
    "# отмечаем их как 1\n",
    "targets_train_lvl2['target'] = 1\n",
    "\n",
    "# объединяем фрейм фактического взаимодействия с предсказанным по совпадению пользователь-товар\n",
    "targets_train_lvl2 = df.merge(targets_train_lvl2, on=['user_id', 'item_id'], how='left')\n",
    "# если появятся не зафиксированные взаимодействия, отметим их как 0 \n",
    "targets_train_lvl2['target'].fillna(0, inplace=True)\n",
    "\n",
    "targets_train_lvl2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Добавление фичей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Добавляем фичи для user, items и user_items\n",
    "targets_train_lvl2 = targets_train_lvl2.merge(item_features, on='item_id', how='left')\n",
    "targets_train_lvl2 = targets_train_lvl2.merge(user_features, on='user_id', how='left')\n",
    "\n",
    "targets_train_lvl2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Разбиваем таргет на X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = targets_train_lvl2.drop('target', axis=1)\n",
    "y_train = targets_train_lvl2[['target']]\n",
    "\n",
    "# Отмечаем категориальные признаки\n",
    "cat_feats = X_train.columns[2:].tolist()\n",
    "X_train[cat_feats] = X_train[cat_feats].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb = LGBMClassifier(objective='binary', max_depth=7, categorical_column=cat_feats)\n",
    "lgb.fit(X_train, y_train)\n",
    "\n",
    "# прогнозирование train выборки\n",
    "train_preds = lgb.predict(X_train)\n",
    "train_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Оценка обучения 2го уровня модели (train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_lgbm(targets, preds, k=5):\n",
    "    targets['recommend'] = preds\n",
    "    targets = targets[['user_id', 'item_id', 'target', 'recommend']]\n",
    "    \n",
    "    target = targets[targets['target'] == 1]\n",
    "    target = target.groupby('user_id')['item_id'].unique().reset_index()\n",
    "    target.columns = ['user_id', 'target']\n",
    "    \n",
    "    recommend = targets[targets['recommend'] == 1]\n",
    "    recommend = recommend.groupby('user_id')['item_id'].unique().reset_index()\n",
    "    recommend.columns = ['user_id', 'recommend']\n",
    "    \n",
    "    target_recommend = target.merge(recommend, on='user_id')\n",
    "    \n",
    "    result = evaluete_rec(data=target_recommend, true='target', metric='precision@k', k=k)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'precision@5 (train) = {eval_lgbm(targets=targets_train_lvl2, preds=train_preds)[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Формирование фремов для прогнозирования на test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_test_lvl2 = test[['user_id', 'item_id']].copy()\n",
    "targets_test_lvl2['target'] = 1\n",
    "\n",
    "targets_test_lvl2 = df.merge(targets_test_lvl2, on=['user_id', 'item_id'], how='left')\n",
    "\n",
    "targets_test_lvl2['target'].fillna(0, inplace= True)\n",
    "\n",
    "targets_test_lvl2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_test_lvl2 = targets_test_lvl2.merge(item_features, on='item_id', how='left')\n",
    "targets_test_lvl2 = targets_test_lvl2.merge(user_features, on='user_id', how='left')\n",
    "\n",
    "targets_test_lvl2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = targets_test_lvl2.drop('target', axis=1)\n",
    "y_test = targets_test_lvl2[['target']]\n",
    "\n",
    "X_test[cat_feats] = X_test[cat_feats].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Прогноз и оценка результатов на test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = lgb.predict(X_test)\n",
    "test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'precision@5 (train) = {eval_lgbm(targets=targets_test_lvl2, preds=test_preds)[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вывод\n",
    "\n",
    "- Двухуровневая модель выдала результат > 0.27 - цель достигнута"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
